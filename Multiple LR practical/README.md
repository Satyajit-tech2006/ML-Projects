ðŸ“˜ Multiple Linear Regression â€“ Practical Recall Notes
======================================================

1ï¸âƒ£ What is Multiple Linear Regression?
---------------------------------------

**Definition**Multiple Linear Regression is used when **more than one independent feature** is used to predict a single continuous output.

y^=Î²0+Î²1x1+Î²2x2+â‹¯+Î²kxk\\hat{y} = \\beta\_0 + \\beta\_1 x\_1 + \\beta\_2 x\_2 + \\dots + \\beta\_k x\_ky^â€‹=Î²0â€‹+Î²1â€‹x1â€‹+Î²2â€‹x2â€‹+â‹¯+Î²kâ€‹xkâ€‹

**When to use**

*   Output is continuous
    
*   Relationship is approximately linear
    
*   More than one influencing feature exists
    

2ï¸âƒ£ Dataset Understanding (What & Why)
--------------------------------------

**Dataset:** economic\_index.csv

**Features**

*   interest\_rate â†’ independent
    
*   unemployment\_rate â†’ independent
    
*   index\_price â†’ dependent (target)
    

**Why drop year, month, Unnamed: 0**

*   They do not influence the target directly
    
*   Keeping them adds noise
    
*   May cause misleading correlations
    

3ï¸âƒ£ Why Data Visualization First
--------------------------------

### Pairplot & Correlation

*   **Why**: To verify linear relationship and detect patterns
    
*   **What it tells**:
    
    *   Strength of relationship
        
    *   Direction (positive/negative)
        
    *   Presence of multicollinearity
        

High correlation with target â†’ good predictorHigh correlation among predictors â†’ potential multicollinearity

4ï¸âƒ£ Feature Selection (Why X is 2D)
-----------------------------------

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   X = df[['interest_rate', 'unemployment_rate']]  y = df['index_price']   `

**Why X must be 2D**

*   sklearn expects shape (n\_samples, n\_features)
    
*   Consistent interface for single or multiple features
    

**Why y can be 1D**

*   Target is a single value per sample
    

5ï¸âƒ£ Trainâ€“Test Split (Why & When)
---------------------------------

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   train_test_split(test_size=0.25, random_state=42)   `

**Why**

*   To test generalization
    
*   Prevent overfitting illusion
    

**random\_state = 42**

*   Ensures reproducibility
    
*   Same split every run
    

6ï¸âƒ£ Why Standard Scaling is Important
-------------------------------------

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   StandardScaler()   `

**Why**

*   Gradient descent converges faster
    
*   Features on different scales do not dominate
    
*   Improves numerical stability
    

**Golden rule**

*   fit\_transform() â†’ training data
    
*   transform() â†’ test & future data(prevents data leakage)
    

7ï¸âƒ£ Model Training (What Happens Internally)
--------------------------------------------

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   LinearRegression().fit(X_train, y_train)   `

*   sklearn uses **Ordinary Least Squares (OLS)**
    
*   Solves equation directly (no iterations)
    

Model learns coefficients:

Î²=(XTX)âˆ’1XTy\\beta = (X^T X)^{-1} X^T yÎ²=(XTX)âˆ’1XTy

8ï¸âƒ£ Meaning of Coefficients
---------------------------

*   **Coefficient (Î²i\\beta\_iÎ²iâ€‹)** â†’ change in target per unit change in feature
    
*   **Intercept (Î²0\\beta\_0Î²0â€‹)** â†’ predicted value when all features = 0
    

Interpretation must be done **after scaling context is understood**.

9ï¸âƒ£ Why Cross-Validation is Used
--------------------------------

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   cross_val_score(scoring='neg_mean_squared_error')   `

**Why**

*   Single train-test split may be misleading
    
*   Cross-validation gives average performance
    
*   Reduces variance in evaluation
    

**Negative MSE**

*   sklearn maximizes scores
    
*   Negative sign allows MSE to fit maximization framework
    

ðŸ”Ÿ Evaluation Metrics (When to Use What)
----------------------------------------

MetricWhyMAEEasy interpretationMSEPenalizes large errorsRMSESame unit as targetRÂ²Variance explainedAdjusted RÂ²Penalizes extra features

**Adjusted RÂ² is preferred in multiple regression**

1ï¸âƒ£1ï¸âƒ£ Residual Analysis (Assumptions Check)
--------------------------------------------

### What to check

*   Residuals should be:
    
    *   Normally distributed
        
    *   Mean â‰ˆ 0
        
    *   No clear pattern vs predictions
        

**Why**

*   Validates linear regression assumptions
    
*   Detects heteroscedasticity & non-linearity
    

1ï¸âƒ£2ï¸âƒ£ OLS with Statsmodels (Why Compare)
-----------------------------------------

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   statsmodels.OLS()   `

**Why**

*   Detailed statistical summary
    
*   Confirms sklearn results
    
*   Shows:
    
    *   p-values
        
    *   F-statistic
        
    *   confidence intervals
        

If coefficients â‰ˆ sklearn â†’ model is correct.

1ï¸âƒ£3ï¸âƒ£ Key Practical Rules (Must Remember)
------------------------------------------

*   Always scale features when using GD-based methods
    
*   Never fit scaler on test data
    
*   X â†’ always 2D
    
*   y â†’ always 1D
    
*   Validate assumptions using residuals
    
*   Adjusted RÂ² > RÂ² for model comparison